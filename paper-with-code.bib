@Article{Meulen2017,
  author    = {Meulen, Frank van der and Schauer, Moritz},
  journal   = {Electronic Journal of Statistics},
  title     = {Bayesian estimation of discretely observed multi-dimensional diffusion processes using guided proposals},
  year      = {2017},
  month     = jan,
  number    = {1},
  pages     = {2358--2396},
  volume    = {11},
  abstract  = {Estimation of parameters of a diffusion based on discrete time observations poses a difficult problem due to the lack of a closed form expression for the likelihood. From a Bayesian computational perspective it can be casted as a missing data problem where the diffusion bridges in between discrete-time observations are missing. The computational problem can then be dealt with using a Markov-chain Monte-Carlo method known as data-augmentation. If unknown parameters appear in the diffusion coefficient, direct implementation of data-augmentation results in a Markov chain that is reducible. Furthermore, data-augmentation requires efficient sampling of diffusion bridges, which can be difficult, especially in the multidimensional case. We present a general framework to deal with with these problems that does not rely on discretisation. The construction generalises previous approaches and sheds light on the assumptions necessary to make these approaches work. We define a random-walk type Metropolis-Hastings sampler for updating diffusion bridges. Our methods are illustrated using guided proposals for sampling diffusion bridges. These are Markov processes obtained by adding a guiding term to the drift of the diffusion. We give general guidelines on the construction of these proposals and introduce a time change and scaling of the guided proposal that reduces discretisation error. Numerical examples demonstrate the performance of our methods.},
  doi       = {10.1214/17-EJS1290},
  file      = {:Meulen2017 - Bayesian Estimation of Discretely Observed Multi Dimensional Diffusion Processes Using Guided Proposals.pdf:PDF},
  groups    = {paper-with-code},
  keywords  = {Data augmentation, discretisation of path integral, FitzHugh-Nagumo model, innovation process, linear process, Multidimensional diffusion bridge, non-centred parametrisation},
  publisher = {Institute of Mathematical Statistics and Bernoulli Society},
  urldate   = {2021-10-06},
}

@Article{Weber2016,
  author     = {Weber, Tobias and Georgii, Robert and B?ni, Peter},
  journal    = {SoftwareX},
  title      = {Takin: {An} open-source software for experiment planning, visualisation, and data analysis},
  year       = {2016},
  issn       = {2352-7110},
  month      = jan,
  pages      = {121--126},
  volume     = {5},
  abstract   = {Due to their non-trivial resolution function, measurements on triple-axis spectrometers require extra care from the experimentalist in order to obtain optimal results and to avoid unwanted spurious artefacts. We present a free and open-source software system that aims to ease many of the tasks encountered during the planning phase, in the execution and in data treatment of experiments performed on neutron triple-axis spectrometers. The software is currently in use and has been successfully tested at the MLZ, but can be configured to work with other triple-axis instruments and instrument control systems.},
  doi        = {10.1016/j.softx.2016.06.002},
  file       = {:Weber2016a - Takin_ an Open Source Software for Experiment Planning, Visualisation, and Data Analysis.html:URL},
  groups     = {paper-with-code},
  keywords   = {Triple-axis spectroscopy, Instrument control, Reciprocal and real space visualisation, Instrument resolution, Resolution convolution},
  language   = {en},
  shorttitle = {Takin},
  url        = {https://www.sciencedirect.com/science/article/pii/S2352711016300152},
  urldate    = {2021-10-06},
}

@Article{Rding2017,
  author    = {R?ding, Magnus},
  journal   = {Soft Matter},
  title     = {Shape-dependent effective diffusivity in packings of hard cubes and cuboids compared with spheres and ellipsoids},
  year      = {2017},
  issn      = {1744-6848},
  month     = nov,
  number    = {46},
  pages     = {8864--8870},
  volume    = {13},
  abstract  = {We performed computational screening of effective diffusivity in different configurations of cubes and cuboids compared with spheres and ellipsoids. In total, more than 1500 structures are generated and screened for effective diffusivity. We studied simple cubic and face-centered cubic lattices of spheres and cubes, random configurations of cubes and spheres as a function of volume fraction and polydispersity, and finally random configurations of ellipsoids and cuboids as a function of shape. We found some interesting shape-dependent differences in behavior, elucidating the impact of shape on the targeted design of granular materials.},
  doi       = {10.1039/C7SM01910F},
  file      = {:Rding2017 - Shape Dependent Effective Diffusivity in Packings of Hard Cubes and Cuboids Compared with Spheres and Ellipsoids.pdf:PDF},
  groups    = {paper-with-code},
  language  = {en},
  publisher = {The Royal Society of Chemistry},
  url       = {https://pubs.rsc.org/en/content/articlelanding/2017/sm/c7sm01910f},
  urldate   = {2021-10-06},
}

@Article{Fox2017,
  author    = {Fox, Alyson and Manteuffel, Thomas and Sanders, Geoffrey},
  journal   = {SIAM Journal on Scientific Computing},
  title     = {Numerical {Methods} for {Gremban}'s {Expansion} of {Signed} {Graphs}},
  year      = {2017},
  issn      = {1064-8275},
  month     = jan,
  number    = {5},
  pages     = {S945--S968},
  volume    = {39},
  abstract  = {Recently a new dimension of graphs has manifested in the network science community that goes beyond the traditional notion of connections and disconnections to include both favorable and adverse relationships. There are many applications, such as ranking and clustering, where data scientists are interested in solving linear systems associated with unsigned graphs. We show that there exists a direct relationship between a signed graph and an unsigned variant. Methods that have been applied for unsigned graphs could be applied to signed graphs in a meaningful way. Fairly robust solvers for unsigned, undirected graph Laplacians have been developed, but these solvers are not directly applicable to general, signed graphs. Gremban's expansion [K. Gremban, Combinatorial Preconditioners for Sparse, Symmetric, Diagonally Dominant Linear Systems, Ph.D. thesis and Tech. report CMU-CS-96-123, School of Computer Science, Carnegie Mellon University, Pittsburgh, 1996] is used to transform the signed, undirected graph Laplacian into an unsigned, undirected graph Laplacian with twice the number of unknowns. The solution to the linear system of the expanded matrix yields the solution of the original linear system. Thus, using Gremban's expansion, we can extend the current Laplacian solvers' robustness to signed graph Laplacians. We hope to further motivate data analysts to use signed graph models by providing optimal solvers and showing how they are related to existing unsigned graph mining techniques applied to the graph associated with the Gremban's expansion matrix. Due to the relationship between a signed graph and its unsigned graph via the Gremban expansion matrix, we conduct a preliminary investigation into the application of traditional ranking to the Gremban's expansion matrix. The rankings using Gremban's expansion for a user-movie rating graph change considerably if a signed graph Laplacian is used, indicating that applications such as recommendation systems would attain different and possibly better recommendations if a signed graph was used instead. This paper delves into the numerical stability and applicability of Gremban's expansion and proves that the error of the solution of the original linear system can be tightly bounded by the error of the expanded system. Gremban's expansion was originally created only for symmetric matrices. This paper demonstrates that the expansion is applicable not only to symmetric diagonally dominant matrices but also to nonsymmetric matrices associated with signed, directed graphs. This paper presents numerical tests on signed, undirected graphs. Both manufactured and real-world signed, undirected graph Laplacians are tested with various solvers to show that the expansion is numerically stable.},
  doi       = {10.1137/16M1082433},
  file      = {:Fox2017 - Numerical Methods for Gremban's Expansion of Signed Graphs.html:URL},
  groups    = {paper-with-code},
  keywords  = {signed graphs, Gremban expansion, graph Laplacian, LAMG},
  publisher = {Society for Industrial and Applied Mathematics},
  urldate   = {2021-10-06},
}

@Article{Kressner2017,
  author   = {Kressner, Daniel and Lana, Peri≈°a},
  journal  = {SIAM Journal on Scientific Computing},
  title    = {Recompression of {Hadamard} {Products} of {Tensors} in {Tucker} {Format}},
  year     = {2017},
  issn     = {1064-8275, 1095-7197},
  month    = jan,
  number   = {5},
  pages    = {A1879--A1902},
  volume   = {39},
  doi      = {10.1137/16M1093896},
  groups   = {paper-with-code},
  language = {en},
  urldate  = {2021-10-06},
}

@InProceedings{Ediger2017,
  author    = {Ediger, David and Fairbanks, James P.},
  booktitle = {2017 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} {Workshops} ({IPDPSW})},
  title     = {Deriving {Streaming} {Graph} {Algorithms} from {Static} {Definitions}},
  year      = {2017},
  month     = may,
  pages     = {637--642},
  abstract  = {Increasing volumes of data and the desire for realtime query capability make the development of efficient streaming algorithms for data analytics valuable. Streaming graph algorithms that avoid unnecessary recomputation through clever application of data dependency analysis are often more complex to derive than their static counterparts. This paper discusses a method to derive algorithms for streaming graph analysis from static formulations Combining tuned graph algorithms building blocks with an appropriate functional language, a graph query planner should be able to correctly implement most static and streaming versions of an algorithm from a single mathematical formulation. We provide a detailed analysis for the case of updating triangle counts in a streaming graph using linear algebra and an experimental evaluation in Julia.},
  doi       = {10.1109/IPDPSW.2017.146},
  groups    = {paper-with-code},
  keywords  = {Algorithm design and analysis, Optimization, Computational modeling, Mathematical model, Linear algebra, Measurement, Database languages, Graph analysis, streaming graphs, triangle counting, GraphBLAS, graph algorithm building blocks (GABB)},
}

@Article{Peng2021,
  author     = {Peng, Ronghua and Han, Bo and Liu, Yajun and Hu, Xiangyun},
  journal    = {GEOPHYSICS},
  title      = {{EM3DANI}: {A} {Julia} package for fully anisotropic {3D} forward modeling of electromagnetic data},
  year       = {2021},
  issn       = {0016-8033},
  month      = sep,
  number     = {5},
  pages      = {F49--F60},
  volume     = {86},
  abstract   = {Forward modeling is vital for 3D inversion and interpretation of electromagnetic (EM) data in anisotropic media, which is one of the major challenges in the field of EM geophysics. However, there are few freely available 3D codes that are capable of modeling EM responses in fully anisotropic media. In addition, most existing 3D EM codes are written in low-level languages (LLs) such as C and Fortran, making them difficult to read, maintain, and extend. Taking advantage of recent progress in computer technology and numerical methods, we have developed an open-source package for forward modeling of frequency-domain EM fields in a fully 3D anisotropic earth (EM3DANI) using the Julia language, a relatively young, high-level programming language with a focus on high performance. Based on a mimetic finite-volume discretization of the governing equations, the modeling algorithm is expressed in an abstract form in terms of matrices/vectors and thus can be easily implemented by using any high-level language commonly used for numerical computing. Existing libraries written in LLs can be easily integrated into a Julia code without the so-called two-language problem; thus, we have exploited several mature third-party packages to deal with computationally intensive parts of the forward modeling, which guarantees high stability and efficiency. We have elaborated the structure of the package, paying special attention to code usability, readability, and extendability, while striving to retain versatility and high performance. The effectiveness of the code is demonstrated through two 1D synthetic examples for magnetotelluric and controlled-source EM (CSEM) problems, respectively. High accuracy and efficiency can be achieved for both 1D examples. Furthermore, we have developed a 3D example mimicking a marine CSEM survey scenario for hydrocarbon exploration. The simulation results indicate that the effect of the anisotropy on forward responses is significant and can be comparable to that of the target reservoir.},
  comment    = {https://github.com/CUG-EMI/EM3DANI},
  doi        = {10.1190/geo2020-0489.1},
  file       = {Full Text PDF:https\://library.seg.org/doi/pdf/10.1190/geo2020-0489.1:application/pdf},
  groups     = {paper-with-code},
  keywords   = {magnetotelluric, CSEM, modeling, 3D, anisotropy},
  publisher  = {Society of Exploration Geophysicists},
  shorttitle = {{EM3DANI}},
  urldate    = {2021-12-04},
}

@Article{Czekala2015,
  author    = {Czekala, I. and Andrews, S. M. and Jensen, E. L. N. and Stassun, K. G. and Torres, G. and Wilner, D. J.},
  journal   = {The Astrophysical Journal},
  title     = {A {DISK}-{BASED} {DYNAMICAL} {MASS} {ESTIMATE} {FOR} {THE} {YOUNG} {BINARY} {AK} {SCO}},
  year      = {2015},
  issn      = {0004-637X},
  month     = jun,
  number    = {2},
  pages     = {154},
  volume    = {806},
  abstract  = {We present spatially and spectrally resolved Atacama Large Millimeter/submillimeter Array (ALMA) observations of gas and dust in the disk orbiting the pre-main sequence (pre-MS) binary AK Sco. By forward-modeling the disk velocity field traced by CO J = 2‚Äì1 line emission, we infer the mass of the central binary, , a new dynamical measurement that is independent of stellar evolutionary models. Assuming the disk and binary are co-planar within ÔΩû2¬∞, this disk-based binary mass measurement is in excellent agreement with constraints from radial velocity monitoring of the combined stellar spectra. These ALMA results are also compared with the standard approach of estimating masses from the location of the binary in the Hertzsprung‚ÄìRussell diagram, using several common pre-MS model grids. These models predict stellar masses that are marginally consistent with our dynamical measurement (at ÔΩû2œÉ), but are systematically high (by ÔΩû10\%). These same models consistently predict an age of 18 ¬± 1 Myr for AK Sco, in line with its membership in the Upper Centaurus‚ÄìLupus association but surprisingly old for it to still host a gas-rich disk. As ALMA accumulates comparable data for large samples of pre-MS stars, the methodology employed here to extract a dynamical mass from the disk rotation curve should prove extraordinarily useful for efforts to characterize the fundamental parameters of early stellar evolution.},
  comment   = {https://github.com/iancze/DiskJockey},
  doi       = {10.1088/0004-637X/806/2/154},
  file      = {:Czekala2015 - A DISK BASED DYNAMICAL MASS ESTIMATE fOR tHE YOUNG BINARY AK SCO.html:URL},
  groups    = {paper-with-code, compat-with-LTS},
  language  = {en},
  publisher = {American Astronomical Society},
  urldate   = {2021-12-04},
}

@Article{Czekala2017,
  author     = {Czekala, Ian and Andrews, Sean M. and Torres, Guillermo and Rodriguez, Joseph E. and Jensen, Eric L. N. and Stassun, Keivan G. and Latham, David W. and Wilner, David J. and Gully-Santiago, Michael A. and Grankin, Konstantin N. and Lund, Michael B. and Kuhn, Rudolf B. and Stevens, Daniel J. and Siverd, Robert J. and James, David and Gaudi, B. Scott and Shappee, Benjamin J. and Holoien, Thomas W.-S.},
  journal    = {The Astrophysical Journal},
  title      = {The {Architecture} of the {GW} {Ori} {Young} {Triple}-star {System} and {Its} {Disk}: {Dynamical} {Masses}, {Mutual} {Inclinations}, and {Recurrent} {Eclipses}},
  year       = {2017},
  issn       = {0004-637X},
  month      = dec,
  number     = {2},
  pages      = {132},
  volume     = {851},
  abstract   = {We present spatially and spectrally resolved Atacama Large Millimeter/submillimeter Array (ALMA) observations of gas and dust orbiting the pre-main-sequence hierarchical triple-star system GW Ori. A forward modeling of the 13CO and C18O J = 2‚Äì1 transitions permits a measurement of the total stellar mass in this system, , and the circumtriple disk inclination, . Optical spectra spanning a 35 yr period were used to derive new radial velocities and, coupled with a spectroscopic disentangling technique, revealed that the A and B components of GW Ori form a double-lined spectroscopic binary with a period of 241.50 ¬± 0.05 days; a tertiary companion orbits that inner pair with a period of 4218 ¬± 50 days. Combining the results from the ALMA data and the optical spectra with three epochs of astrometry in the literature, we constrain the individual stellar masses in the system (, , ) and find strong evidence that at least one of the stellar orbital planes (and likely both) is misaligned with the disk plane by as much as 45¬∞. A V-band light curve spanning 30 yr reveals several new ÔΩû30-day eclipse events 0.1‚Äì0.7 mag in depth and a 0.2 mag sinusoidal oscillation that is clearly phased with the AB‚ÄìC orbital period. Taken together, these features suggest that the A‚ÄìB pair may be partially obscured by material in the inner disk as the pair approaches apoastron in the hierarchical orbit. Lastly, we conclude that stellar evolutionary models are consistent with our measurements of the masses and basic photospheric properties if the GW Ori system is ÔΩû1 Myr old.},
  comment    = {https://github.com/iancze/DiskJockey},
  doi        = {10.3847/1538-4357/aa9be7},
  file       = {IOP Full Text PDF:https\://iopscience.iop.org/article/10.3847/1538-4357/aa9be7/pdf:application/pdf},
  groups     = {paper-with-code, compat-with-LTS},
  language   = {en},
  publisher  = {American Astronomical Society},
  shorttitle = {The {Architecture} of the {GW} {Ori} {Young} {Triple}-star {System} and {Its} {Disk}},
  urldate    = {2021-12-04},
}

@Article{BonnetLebrun2017,
  author   = {{Bonnet-Lebrun}, Anne-Sophie and Manica, Andrea and Eriksson, Anders and Rodrigues, Ana S. L.},
  journal  = {EVOLUTION},
  title    = {Empirical Phylogenies and Species Abundance Distributions Are Consistent with Preequilibrium Dynamics of Neutral Community Models with Gene Flow},
  year     = {2017},
  issn     = {0014-3820},
  month    = may,
  number   = {5},
  pages    = {1149--1163},
  volume   = {71},
  abstract = {Community characteristics reflect past ecological and evolutionary dynamics. Here, we investigate whether it is possible to obtain realistically shaped modeled communities-that is with phylogenetic trees and species abundance distributions shaped similarly to typical empirical bird and mammal communities-from neutral community models. To test the effect of gene flow, we contrasted two spatially explicit individual-based neutral models: one with protracted speciation, delayed by gene flow, and one with point mutation speciation, unaffected by gene flow. The former produced more realistic communities (shape of phylogenetic tree and species-abundance distribution), consistent with gene flow being a key process in macro-evolutionary dynamics. Earlier models struggled to capture the empirically observed branching tempo in phylogenetic trees, as measured by the gamma statistic. We show that the low gamma values typical of empirical trees can be obtained in models with protracted speciation, in preequilibrium communities developing from an initially abundant and widespread species. This was even more so in communities sampled incompletely, particularly if the unknown species are the youngest. Overall, our results demonstrate that the characteristics of empirical communities that we have studied can, to a large extent, be explained through a purely neutral model under preequilibrium conditions.},
  doi      = {10.1111/evo.13228},
  groups   = {paper-with-code},
}

@Article{Cances2017,
  author   = {Cances, Eric and Cazeaux, Paul and Luskin, Mitchell},
  journal  = {JOURNAL OF MATHEMATICAL PHYSICS},
  title    = {Generalized {{Kubo}} Formulas for the Transport Properties of Incommensurate {{2D}} Atomic Heterostructures},
  year     = {2017},
  issn     = {0022-2488},
  month    = jun,
  number   = {6},
  volume   = {58},
  abstract = {We give an exact formulation for the transport coefficients of incommensurate two-dimensional atomic multilayer systems in the tight-binding approximation. This formulation is based upon the C* algebra framework introduced by Bellissard and collaborators [Coherent and Dissipative Transport in Aperiodic Solids, Lecture Notes in Physics (Springer, 2003), Vol. 597, pp. 413-486 and J. Math. Phys. 35(10), 5373-5451 (1994)] to study aperiodic solids (disordered crystals, quasicrystals, and amorphous materials), notably in the presence of magnetic fields (quantum Hall effect). We also present numerical approximations and test our methods on a one-dimensional incommensurate bilayer system. Published by AIP Publishing.},
  doi      = {10.1063/1.4984041},
}

@Article{Chun2017,
  author   = {Chun, Young Jin and Cotton, Simon L. and Dhillon, Harpreet S. and {Javier Lopez-Martinez}, F. and Paris, Jose F. and Yoo, Seong Ki},
  journal  = {IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS},
  title    = {A {{Comprehensive Analysis}} of {{5G Heterogeneous Cellular Systems Operating Over}} Kappa-Mu {{Shadowed Fading Channels}}},
  year     = {2017},
  issn     = {1536-1276},
  month    = nov,
  number   = {11},
  pages    = {6995--7010},
  volume   = {16},
  abstract = {Emerging cellular technologies such as those proposed for use in 5G communications will accommodate a wide range of usage scenarios with diverse link requirements. This will necessitate operation over a versatile set of wireless channels ranging from indoor to outdoor, from line-of-sight (LOS) to non-LOS, and from circularly symmetric scattering to environments which promote the clustering of scattered multipath waves. Unfortunately, many of the conventional fading models lack the flexibility to account for such disparate signal propagation mechanisms. To bridge the gap between theory and practical channels, we consider mu-kappa shadowed fading, which contains as special cases the majority of the linear fading models proposed in the open literature. In particular, we propose an analytic framework to evaluate the average of an arbitrary function of the signal-to-noise-plus-interference ratio (SINR) over mu-kappa shadowed fading channels by using an orthogonal expansion with tools from stochastic geometry. Using the proposed method, we evaluate the spectral efficiency, moments of the SINR, and outage probability of a K-tier heterogeneous cellular network with K classes of base stations (BSs), differing in terms of the transmit power, BS density, shadowing, and fading characteristics. Building upon these results, we provide important new insights into the network performance of these emerging wireless applications while considering a diverse range of fading conditions and link qualities.},
  doi      = {10.1109/TWC.2017.2734080},
}

@Article{Devaney2017,
  author   = {Devaney, Nicholas and Thiebaut, Eric},
  journal  = {MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY},
  title    = {{{PEX}} 1. {{Multispectral}} Expansion of Residual Speckles for Planet Detection},
  year     = {2017},
  issn     = {0035-8711},
  month    = dec,
  number   = {3},
  pages    = {3734--3748},
  volume   = {472},
  abstract = {The detection of exoplanets in coronographic images is severely limited by residual starlight speckles. Dedicated post-processing can drastically reduce this 'stellar leakage' and thereby increase the faintness of detectable exoplanets. Based on a multispectral series expansion of the diffraction pattern, we derive a multimode model of the residuals which can be exploited to estimate and thus remove the residual speckles in multispectral coronographic images. Compared to other multispectral processing methods, our model is physically grounded and is suitable for use in an (optimal) inverse approach. We demonstrate the ability of our model to correctly estimate the speckles in simulated data and demonstrate that very high contrasts can be achieved. We further apply our method to removing speckle from a real data cube obtained with the SPHERE integral field spectrograph instrument.},
  doi      = {10.1093/mnras/stx2218},
}

@Article{Devine2017,
  author   = {Devine, Jack and Jack, M. W.},
  journal  = {PHYSICAL REVIEW E},
  title    = {Self-Induced Temperature Gradients in {{Brownian}} Dynamics},
  year     = {2017},
  issn     = {2470-0045},
  month    = dec,
  number   = {6},
  volume   = {96},
  abstract = {Brownian systems often surmount energy barriers by absorbing and emitting heat to and from their local environment. Usually, the temperature gradients created by this heat exchange are assumed to dissipate instantaneously. Here we relax this assumption to consider the case where Brownian dynamics on a time-independent potential can lead to self-induced temperature gradients. In the same way that externally imposed temperature gradients can cause directed motion, these self-induced gradients affect the dynamics of the Brownian system. The result is a coupling between the local environment and the Brownian subsystem. We explore the resulting dynamics and thermodynamics of these coupled systems and develop a robust method for numerical simulation. In particular, by focusing on one-dimensional situations, we show that self-induced temperature gradients reduce barrier-crossing rates. We also consider a heat engine and a heat pump based on temperature gradients induced by a Brownian system in a nonequilibrium potential.},
  doi      = {10.1103/PhysRevE.96.062130},
}

@Article{Drogoul2017,
  author   = {Drogoul, Audric and Veltz, Romain},
  journal  = {CHAOS},
  title    = {Hopf Bifurcation in a Nonlocal Nonlinear Transport Equation Stemming from Stochastic Neural Dynamics},
  year     = {2017},
  issn     = {1054-1500},
  month    = feb,
  number   = {2},
  volume   = {27},
  abstract = {In this work, we provide three different numerical evidences for the occurrence of a Hopf bifurcation in a recently derived [De Masi et al., J. Stat. Phys. 158, 866-902 (2015) and Fournier and locherbach, Ann. Inst. H. Poincare Probab. Stat. 52, 1844-1876 (2016)] mean field limit of a stochastic network of excitatory spiking neurons. The mean field limit is a challenging nonlocal nonlinear transport equation with boundary conditions. The first evidence relies on the computation of the spectrum of the linearized equation. The second stems from the simulation of the full mean field. Finally, the last evidence comes from the simulation of the network for a large number of neurons. We provide a "recipe" to find such bifurcation which nicely complements the works in De Masi et al. [J. Stat. Phys. 158, 866-902 (2015)] and Fournier and locherbach [Ann. Inst. H. Poincare Probab. Stat. 52, 1844-1876 (2016)]. This suggests in return to revisit theoretically these mean field equations from a dynamical point of view. Finally, this work shows how the noise level impacts the transition from asynchronous activity to partial synchronization in excitatory globally pulse-coupled networks. Published by AIP Publishing.},
  doi      = {10.1063/1.4976510},
}

@Article{Dunning2017,
  author   = {Dunning, Iain and Huchette, Joey and Lubin, Miles},
  journal  = {SIAM REVIEW},
  title    = {{{JuMP}}: A {{Modeling Language}} for {{Mathematical Optimization}}},
  year     = {2017},
  issn     = {0036-1445},
  number   = {2},
  pages    = {295--320},
  volume   = {59},
  abstract = {JuMP is an open-source modeling language that allows users to express a wide range of optimization problems (linear, mixed-integer, quadratic, conic-quadratic, semidefinite, and nonlinear) in a high-level, algebraic syntax. JuMP takes advantage of advanced features of the Julia programming language to offer unique functionality while achieving performance on par with commercial modeling tools for standard tasks. In this work we will provide benchmarks, present the novel aspects of the implementation, and discuss how JuMP can be extended to new problem classes and composed with state-of-the-art tools for visualization and interactivity.},
  comment  = {https://github.com/jump-dev/JuMP.jl},
  doi      = {10.1137/15M1020575},
  groups   = {paper-with-code, compat-with-LTS},
}

@Article{Dussault2017,
  author   = {Dussault, Jean-Pierre},
  journal  = {OPERATIONS RESEARCH LETTERS},
  title    = {A Note on Robust Descent in Differentiable Optimization},
  year     = {2017},
  issn     = {0167-6377},
  month    = sep,
  number   = {5},
  pages    = {530--532},
  volume   = {45},
  abstract = {In this note, we show how to alleviate the catastrophic cancellations that occur when comparing function values in trust-region algorithms. The main original contribution is to successfully adapt the line search strategy Hager and Zhang (2005) for use within trust-region-like algorithms. (C) 2017 Published by Elsevier B.V.},
  doi      = {10.1016/j.orl.2017.08.009},
}

@InProceedings{Falt2017,
  author    = {Falt, Mattias and Giselsson, Pontus and {IEEE}},
  booktitle = {2017 {{IEEE 56TH ANNUAL CONFERENCE ON DECISION AND CONTROL}} ({{CDC}})},
  title     = {Optimal {{Convergence Rates}} for {{Generalized Alternating Projections}}},
  year      = {2017},
  abstract  = {Generalized alternating projections is an algorithm that alternates relaxed projections onto a finite number of sets to find a point in their intersection. We consider the special case of two linear subspaces, for which the algorithm reduces to matrix multiplications. For convergent powers of the matrix, the asymptotic rate is linear and decided by the magnitude of the subdominant eigenvalue. In this paper, we show how to select the three algorithm parameters to optimize this magnitude, and hence the asymptotic convergence rate. The obtained rate depends on the Friedrichs angle between the subspaces and is considerably better than known rates for other methods such as alternating projections and Douglas-Rachford splitting. We also present an adaptive scheme that, online, estimates the Friedrichs angle and updates the algorithm parameters based on this estimate. A numerical example is provided that supports our theoretical claims and shows very good performance for the adaptive method.},
  isbn      = {0743-1546},
}

@Article{FernandezdeCossioDiaz2017,
  author   = {{Fernandez-de-Cossio-Diaz}, Jorge and Leon, Kalet and Mulet, Roberto},
  journal  = {PLOS COMPUTATIONAL BIOLOGY},
  title    = {Characterizing Steady States of Genome-Scale Metabolic Networks in Continuous Cell Cultures},
  year     = {2017},
  issn     = {1553-7358},
  month    = nov,
  number   = {11},
  volume   = {13},
  abstract = {In the continuous mode of cell culture, a constant flow carrying fresh media replaces culture fluid, cells, nutrients and secreted metabolites. Here we present a model for continuous cell culture coupling intra-cellular metabolism to extracellular variables describing the state of the bioreactor, taking into account the growth capacity of the cell and the impact of toxic byproduct accumulation. We provide a method to determine the steady states of this system that is tractable for metabolic networks of arbitrary complexity. We demonstrate our approach in a toy model first, and then in a genome-scale metabolic network of the Chinese hamster ovary cell line, obtaining results that are in qualitative agreement with experimental observations. We derive a number of consequences from the model that are independent of parameter values. The ratio between cell density and dilution rate is an ideal control parameter to fix a steady state with desired metabolic properties. This conclusion is robust even in the presence of multi-stability, which is explained in our model by a negative feedback loop due to toxic byproduct accumulation. A complex landscape of steady states emerges from our simulations, including multiple metabolic switches, which also explain why cell-line and media benchmarks carried out in batch culture cannot be extrapolated to perfusion. On the other hand, we predict invariance laws between continuous cell cultures with different parameters. A practical consequence is that the chemostat is an ideal experimental model for large-scale high-density perfusion cultures, where the complex landscape of metabolic transitions is faithfully reproduced.},
  doi      = {10.1371/journal.pcbi.1005835},
}

@Article{ForemanMackey2017,
  author   = {{Foreman-Mackey}, Daniel and Agol, Eric and Ambikasaran, Sivaram and Angus, Ruth},
  journal  = {ASTRONOMICAL JOURNAL},
  title    = {Fast and {{Scalable Gaussian Process Modeling}} with {{Applications}} to {{Astronomical Time Series}}},
  year     = {2017},
  issn     = {0004-6256},
  month    = dec,
  number   = {6},
  volume   = {154},
  abstract = {The growing field of large-scale time domain astronomy requires methods for probabilistic data analysis that are computationally tractable, even with large data sets. Gaussian processes (GPs) are a popular class of models used for this purpose, but since the computational cost scales, in general, as the cube of the number of data points, their application has been limited to small data sets. In this paper, we present a novel method for GPs modeling in one dimension where the computational requirements scale linearly with the size of the data set. We demonstrate the method by applying it to simulated and real astronomical time series data sets. These demonstrations are examples of probabilistic inference of stellar rotation periods, asteroseismic oscillation spectra, and transiting planet parameters. The method exploits structure in the problem when the covariance function is expressed as a mixture of complex exponentials, without requiring evenly spaced observations or uniform noise. This form of covariance arises naturally when the process is a mixture of stochastically driven damped harmonic oscillators-providing a physical motivation for and interpretation of this choice-but we also demonstrate that it can be a useful effective model in some other cases. We present a mathematical description of the method and compare it to existing scalable GP methods. The method is fast and interpretable, with a range of potential applications within astronomical data analysis and beyond. We provide well-tested and documented open-source implementations of this method in C++, Python, and Julia.},
  doi      = {10.3847/1538-3881/aa9332},
}

@Article{Frost2017,
  author   = {Frost, Jarvist Moore},
  journal  = {PHYSICAL REVIEW B},
  title    = {Calculating Polaron Mobility in Halide Perovskites},
  year     = {2017},
  issn     = {2469-9950},
  month    = nov,
  number   = {19},
  volume   = {96},
  abstract = {Lead halide perovskite semiconductors are soft, polar materials. The strong driving force for polaron formation (the dielectric electron-phonon coupling) is balanced by the light band effective masses, leading to a strongly-interacting large polaron. A first-principles prediction of mobility would help understand the fundamental mobility limits. Theories of mobility need to consider the polaron (rather than free-carrier) state due to the strong interactions. In this material we expect that at room temperature polar-optical phonon mode scattering will dominate and so limit mobility. We calculate the temperature-dependent polaron mobility of hybrid halide perovskites by variationally solving the Feynman polaron model with the finite-temperature free energies of Osaka. This model considers a simplified effective-mass band structure interacting with a continuum dielectric of characteristic response frequency. We parametrize the model fully from electronic-structure calculations. In methylammonium lead iodide at 300 K we predict electron and hole mobilities of 133 and 94 cm(2) V-1 s(-1), respectively. These are in acceptable agreement with single-crystal measurements, suggesting that the intrinsic limit of the polaron charge carrier state has been reached. Repercussions for hot-electron photoexcited states are discussed. As well as mobility, the model also exposes the dynamic structure of the polaron. This can be used to interpret impedance measurements of the charge-carrier state. We provide the phonon-drag mass renormalization and scattering time constants. These could be used as parameters for larger-scale device models and band-structure dependent mobility simulations.},
  doi      = {10.1103/PhysRevB.96.195202},
}

@InProceedings{Incerto2017,
  author    = {Incerto, Emilio and Tribastone, Mirco and Trubiani, Catia},
  booktitle = {{{PROCEEDINGS OF THE}} 2017 {{32ND IEEE}}/{{ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING}} ({{ASE}}'17)},
  title     = {Software {{Performance Self}}-{{Adaptation}} through {{Efficient Model Predictive Control}}},
  year      = {2017},
  editor    = {Rosu, G and DiPenta, M and Nguyen, TN},
  pages     = {485--496},
  abstract  = {A key challenge in software systems that are exposed to runtime variabilities, such as workload fluctuations and service degradation, is to continuously meet performance requirements. In this paper we present an approach that allows performance self-adaptation using a system model based on queuing networks (QNs), a well-assessed formalism for software performance engineering. Software engineers can select the adaptation knobs of a QN (routing probabilities, service rates, and concurrency level) and we automatically derive a Model Predictive Control (MPC) formulation suitable to continuously configure the selected knobs and track the desired performance requirements. Previous MPC approaches have two main limitations: i) high computational cost of the optimization, due to nonlinearity of the models; ii) focus on long-run performance metrics only, due to the lack of tractable representations of the QN's time-course evolution. As a consequence, these limitations allow adaptations with coarse time granularities, neglecting the system's transient behavior. Our MPC adaptation strategy is efficient since it is based on mixed integer programming, which uses a compact representation of a QN with ordinary differential equations. An extensive evaluation on an implementation of a load balancer demonstrates the effectiveness of the adaptation and compares it with traditional methods based on probabilistic model checking.},
  isbn      = {1527-1366},
}

@Article{Jalving2017,
  author   = {Jalving, Jordan and Abhyankar, Shrirang and Kim, Kibaek and Hereld, Mark and Zavala, Victor M.},
  journal  = {IET GENERATION TRANSMISSION \& DISTRIBUTION},
  title    = {A Graph-Based Computational Framework for Simulation and Optimisation of Coupled Infrastructure Networks},
  year     = {2017},
  issn     = {1751-8687},
  month    = aug,
  number   = {12},
  pages    = {3163--3176},
  volume   = {11},
  abstract = {The authors present a graph-based computational framework that facilitates the construction, instantiation, and analysis of large-scale optimisation and simulation applications of coupled infrastructure networks. The framework integrates the optimisation modelling package PLASMO and the simulation package DMNetwork (built around PETSc). These tools use a common graph-based modelling abstraction that enables them to achieve compatibility between interfaces and data structures and facilitates the modular creation and exchange of component models. The authors also describe how to embed these tools within complex computational workflows using SWIFT, which is a tool that facilitates parallel execution of multiple simulation runs and management of input and output data. Finally, the authors discuss how to use these capabilities to target coupled natural gas and electricity systems.},
  doi      = {10.1049/iet-gtd.2016.1582},
}

@Article{Lorch2017,
  author   = {Lorch, Niels and Nigg, Simon E. and Nunnenkamp, Andreas and Tiwari, Rakesh P. and Bruder, Christoph},
  journal  = {PHYSICAL REVIEW LETTERS},
  title    = {Quantum {{Synchronization Blockade}}: Energy {{Quantization Hinders Synchronization}} of {{Identical Oscillators}}},
  year     = {2017},
  issn     = {0031-9007},
  month    = jun,
  number   = {24},
  volume   = {118},
  abstract = {Classically, the tendency towards spontaneous synchronization is strongest if the natural frequencies of the self-oscillators are as close as possible. We show that this wisdom fails in the deep quantum regime, where the uncertainty of amplitude narrows down to the level of single quanta. Under these circumstances identical self-oscillators cannot synchronize and detuning their frequencies can actually help synchronization. The effect can be understood in a simple picture: Interaction requires an exchange of energy. In the quantum regime, the possible quanta of energy are discrete. If the extractable energy of one oscillator does not exactly match the amount the second oscillator may absorb, interaction, and thereby synchronization, is blocked. We demonstrate this effect, which we coin quantum synchronization blockade, in the minimal example of two Kerr-type self-oscillators and predict consequences for small oscillator networks, where synchronization between blocked oscillators can be mediated via a detuned oscillator. We also propose concrete implementations with superconducting circuits and trapped ions. This paves the way for investigations of new quantum synchronization phenomena in oscillator networks both theoretically and experimentally.},
  doi      = {10.1103/PhysRevLett.118.243602},
}

@Article{Medina2017,
  author   = {Medina, Anibal D. and Schmidt, Michael A.},
  journal  = {JOURNAL OF HIGH ENERGY PHYSICS},
  title    = {Enlarging Regions of the {{MSSM}} Parameter Space for Large Tan Beta via {{SUSY}} Decays of the Heavy {{Higgs}} Bosons},
  year     = {2017},
  issn     = {1029-8479},
  month    = aug,
  number   = {8},
  abstract = {In the Minimal Supersymmetric Standard Model (MSSM) searches for the heaviest CP-even and CP-odd Higgs H, A to tau-lepton pairs severely constrain the parameter region for large values of tan beta and light Higgs bosons H, A. We demonstrate how the experimental constraint can be avoided by new decays to light third-generation sfermions, whose left-right couplings to H can be maximised in regions of large trilinear couplings A (b) , A (tau) for sbottoms and staus, or large supersymmetric (SUSY) Higgs mass mu for stops. Due to the tan beta-enhancement in the production cross-sections via gluon-fusion and in association with bottom-quark pairs for H and A, we find that down-type sfermions, in particular, sbottoms perform a better job in allowing more parameter space than up-type sfermions such as stops, which require much larger values of mu to compensate for tan beta. Vacuum stability as well as flavour observables constraints and direct searches for SUSY particles are imposed. We also associate the lightest CP-even Higgs with the observed 125 GeV SM-like Higgs and impose the experimental constraints from the LHC.},
  doi      = {10.1007/JHEP08(2017)095},
}

@Article{Recanati2017,
  author   = {Recanati, Antoine and Bruls, Thomas and {d'Aspremont}, Alexandre},
  journal  = {BIOINFORMATICS},
  title    = {A Spectral Algorithm for Fast de Novo Layout of Uncorrected Long Nanopore Reads},
  year     = {2017},
  issn     = {1367-4803},
  month    = oct,
  number   = {20},
  pages    = {3188--3194},
  volume   = {33},
  abstract = {Motivation: New long read sequencers promise to transform sequencing and genome assembly by producing reads tens of kilobases long. However, their high error rate significantly complicates assembly and requires expensive correction steps to layout the reads using standard assembly engines.Results: We present an original and efficient spectral algorithm to layout the uncorrected nanopore reads, and its seamless integration into a straightforward overlap/layout/consensus (OLC) assembly scheme. The method is shown to assemble Oxford Nanopore reads from several bacterial genomes into good quality (similar to 99\% identity to the reference) genome-sized contigs, while yielding more fragmented assemblies from the eukaryotic microbe Sacharomyces cerevisiae.},
  doi      = {10.1093/bioinformatics/btx370},
}

@Article{Ryan2017,
  author   = {Ryan, Colm A. and Johnson, Blake R. and Riste, Diego and Donovan, Brian and Ohki, Thomas A.},
  journal  = {REVIEW OF SCIENTIFIC INSTRUMENTS},
  title    = {Hardware for Dynamic Quantum Computing},
  year     = {2017},
  issn     = {0034-6748},
  month    = oct,
  number   = {10},
  volume   = {88},
  abstract = {We describe the hardware, gateware, and software developed at Raytheon BBN Technologies for dynamic quantum information processing experiments on superconducting qubits. In dynamic experiments, real-time qubit state information is fed back or fed forward within a fraction of the qubits' coherence time to dynamically change the implemented sequence. The hardware presented here covers both control and readout of superconducting qubits. For readout, we created a custom signal processing gateware and software stack on commercial hardware to convert pulses in a heterodyne receiver into qubit state assignments with minimal latency, alongside data taking capability. For control, we developed custom hardware with gateware and software for pulse sequencing and steering information distribution that is capable of arbitrary control flow in a fraction of superconducting qubit coherence times. Both readout and control platforms make extensive use of field programmable gate arrays to enable tailored qubit control systems in a reconfigurable fabric suitable for iterative development. Published by AIP Publishing.},
  doi      = {10.1063/1.5006525},
}

@Article{Schmiester2017,
  author   = {Schmiester, Leonard and Moeddel, Martin and Erb, Wolfgang and Knopp, Tobias},
  journal  = {IEEE TRANSACTIONS ON COMPUTATIONAL IMAGING},
  title    = {Direct {{Image Reconstruction}} of {{Lissajous}}-{{Type Magnetic Particle Imaging Data Using Chebyshev}}-{{Based Matrix Compression}}},
  year     = {2017},
  issn     = {2333-9403},
  month    = dec,
  number   = {4},
  pages    = {671--681},
  volume   = {3},
  abstract = {Image reconstruction in magnetic particle imaging (MPI) is done using an algebraic approach for Lissajous-type measurement sequences. By solving a large linear system of equations, the spatial distribution of magnetic nanoparticles can be determined. Despite the use of iterative solvers that converge rapidly, the size of the MPI system matrix leads to reconstruction times that are typically much longer than the actual data acquisition time. For this reason, matrix compression techniques have been introduced that transform the MPI system matrix into a sparse domain and then utilize this sparsity for accelerated reconstruction. Within this work, we investigate the Chebyshev transformation for matrix compression and show that it can provide better reconstruction results for high compression rates than the commonly applied Cosine transformation. By reducing the number of coefficients per matrix row to one, it is even possible to derive a direct reconstruction method that obviates the usage of iterative solvers.},
  doi      = {10.1109/TCI.2017.2706058},
}

@Article{Shukron2017,
  author   = {Shukron, Ofir and Hauer, Michael and Holcman, David},
  journal  = {SCIENTIFIC REPORTS},
  title    = {Two Loci Single Particle Trajectories Analysis: Constructing a First Passage Time Statistics of Local Chromatin Exploration},
  year     = {2017},
  issn     = {2045-2322},
  month    = sep,
  volume   = {7},
  abstract = {Stochastic single particle trajectories are used to explore the local chromatin organization. We present here a statistical analysis of the first contact time distributions between two tagged loci recorded experimentally. First, we extract the association and dissociation times from data for various genomic distances between loci, and we show that the looping time occurs in confined nanometer regions. Second, we characterize the looping time distribution for two loci in the presence of multiple DNA damages. Finally, we construct a polymer model, that accounts for the local chromatin organization before and after a double-stranded DNA break (DSB), to estimate the level of chromatin decompaction. This novel passage time statistics method allows extracting transient dynamic at scales varying from one to few hundreds of nanometers, it predicts the local changes in the number of binding molecules following DSB and can be used to characterize the local dynamic of the chromatin.},
  doi      = {10.1038/s41598-017-10842-9},
}

@InProceedings{Thankachan2017,
  author    = {Thankachan, Rohit Varkey and Hein, Eric R. and Swenson, Brian P. and Fairbanks, James P. and {IEEE}},
  booktitle = {2017 {{IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE}} ({{HPEC}})},
  title     = {Integrating {{Productivity}}-{{Oriented Programming Languages}} with {{High}}-{{Performance Data Structures}}},
  year      = {2017},
  abstract  = {This paper shows that Julia provides sufficient performance to bridge the performance gap between productivity-oriented languages and low-level languages for complex memory intensive computation tasks such as graph traversal. We provide performance guidelines for using complex low-level data structures in high productivity languages and present the first parallel integration on the productivity-oriented language side for graph analysis. Performance on the Graph500 benchmark demonstrates that the Julia implementation is competitive with the native C/OpenMP implementation.},
  isbn      = {2377-6943},
}

@Article{Thiebaut2017,
  author   = {Thiebaut, Eric and Young, John},
  journal  = {JOURNAL OF THE OPTICAL SOCIETY OF AMERICA A-OPTICS IMAGE SCIENCE AND VISION},
  title    = {Principles of Image Reconstruction in Optical Interferometry: Tutorial},
  year     = {2017},
  issn     = {1084-7529},
  month    = jun,
  number   = {6},
  pages    = {904--923},
  volume   = {34},
  abstract = {This paper provides a general introduction to the problem of image reconstruction from interferometric data. A simple model of the interferometric observables is given, and the issues arising from sparse Fourier data are discussed. The effects of various regularizations are described. In the proposed general framework, most existing algorithms can be understood. For an astronomer, such an understanding is crucial not only for selecting and using an algorithm but also to ensure correct interpretation of the resulting image. (C) 2017 Optical Society of America},
  doi      = {10.1364/JOSAA.34.000904},
}

@Article{Wagemakers2017,
  author   = {Wagemakers, Alexandre and Sanjuan, Miguel A. F.},
  journal  = {SCIENTIFIC REPORTS},
  title    = {A New Method to Reduce the Number of Time Delays in a Network},
  year     = {2017},
  issn     = {2045-2322},
  month    = jun,
  volume   = {7},
  abstract = {Time delays may cause dramatic changes to the dynamics of interacting oscillators. Coupled networks of interacting dynamical systems can have unexpected behaviours when the signal between the vertices are time delayed. It has been shown for a very general class of systems that the time delays can be rearranged as long as the total time delay over the constitutive loops of the network is conserved. This fact allows to reduce the number of time delays of the problem without loss of information. There is a theoretical lower bound for this number that can be numerically improved if the time delays are commensurable. Here we propose a formulation of the problem and a numerical method to even further reduce the number of time delays in a network.},
  doi      = {10.1038/s41598-017-02978-5},
}

@Article{Weber2017,
  author   = {Weber, Tobias},
  journal  = {SOFTWAREX},
  title    = {Update 1.5 to "{{Takin}}: An Open-Source Software for Experiment Planning, Visualisation, and Data Analysis'', ({{PII}}: S2352711016300152)},
  year     = {2017},
  issn     = {2352-7110},
  pages    = {148--149},
  volume   = {6},
  abstract = {We present an updated version of our inelastic neutron scattering software package Takin, which is a programme for neutron triple-axis experiment planning and evaluation. The new version features several additional programme modules mainly concerning three-dimensional calculations and visualisations. In addition, existing modules have been improved and extended. (C) 2017 The Author. Published by Elsevier B.V.},
  doi      = {10.1016/j.softx.2017.06.002},
}

@InProceedings{Zia2017,
  author    = {Zia, Saman and Yuksel, Buket and Yuret, Deniz and Yemez, Yucel and {IEEE}},
  booktitle = {2017 {{IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS}} ({{ICCVW}} 2017)},
  title     = {{{RGB}}-{{D Object Recognition Using Deep Convolutional Neural Networks}}},
  year      = {2017},
  pages     = {887--894},
  abstract  = {We address the problem of object recognition from RGB-D images using deep convolutional neural networks (CNNs). We advocate the use of 3D CNNs to fully exploit the 3D spatial information in depth images as well as the use of pretrained 2D CNNs to learn features from RGB-D images. There exists currently no large scale dataset available comprising depth information as compared to those for RGB data. Hence transfer learning from 2D source data is key to be able to train deep 3D CNNs. To this end, we propose a hybrid 2D/3D convolutional neural network that can be initialized with pretrained 2D CNNs and can then be trained over a relatively small RGB-D dataset. We conduct experiments on the Washington dataset involving RGB-D images of small household objects. Our experiments show that the features learnt from this hybrid structure, when fused with the features learnt from depth-only and RGB-only architectures, outperform the state of the art on RGB-D category recognition.},
  doi       = {10.1109/ICCVW.2017.109},
  isbn      = {2473-9936},
}

@Article{Rackauckas2017,
  author    = {Rackauckas, Christopher and Nie, Qing},
  journal   = {Journal of Open Research Software},
  title     = {{DifferentialEquations}.jl ‚Äì {A} {Performant} and {Feature}-{Rich} {Ecosystem} for {Solving} {Differential} {Equations} in {Julia}},
  year      = {2017},
  issn      = {2049-9647},
  month     = may,
  number    = {1},
  pages     = {15},
  volume    = {5},
  abstract  = {DifferentialEquations.jl is a package for solving differential equations in Julia. It covers discrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations), ordinary differential equations, stochastic differential equations, algebraic differential equations, delay differential equations, hybrid differential equations, jump diffusions, and (stochastic) partial differential equations. Through extensive use of multiple dispatch, metaprogramming, plot recipes, foreign function interfaces (FFI), and call-overloading, DifferentialEquations.jl offers a unified user interface to solve and analyze various forms of differential equations while not sacrificing features or performance. Many modern features are integrated into the solvers, such as allowing arbitrary user-defined number systems for high-precision and arithmetic with physical units, built-in multithreading and parallelism, and symbolic calculation of Jacobians. Integrated into the package is an algorithm testing and benchmarking suite to both ensure accuracy and serve as an easy way for researchers to develop and distribute their own methods. Together, these features build a highly extendable suite which is feature-rich and highly performant.  Funding statement: This work was partially supported by NIH grants P50GM76516 and R01GM107264 and NSF grants DMS1562176 and DMS1161621. This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1321846, the National Academies of Science, Engineering, and Medicine via the Ford Foundation, and the National Institutes of Health Award T32 EB009418. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the NIH.},
  comment   = {https://github.com/SciML/DifferentialEquations.jl},
  copyright = {Authors who publish with this journal agree to the following terms: Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a Creative Commons Attribution License that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal. Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal. Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See The Effect of Open Access ). All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on Educational Fair Use , please see this useful checklist prepared by Columbia University Libraries . All copyright of third-party content posted here for research purposes belongs to its original owners. Unless otherwise stated all references to characters and comic art presented on this journal are ?, ? or ? of their respective owners. No challenge to any owner‚Äôs rights is intended or should be inferred.},
  doi       = {10.5334/jors.151},
  file      = {Full Text PDF:http\://openresearchsoftware.metajnl.com/articles/10.5334/jors.151/galley/245/download/:application/pdf},
  groups    = {paper-with-code, compat-with-LTS},
  keywords  = {Julia, ordinary differential equations, stochastic differential equations, partial differential equations, multiple dispatch, metaprogramming, high-precision, multithreading},
  language  = {en},
  publisher = {Ubiquity Press},
  urldate   = {2021-12-05},
}

@Article{Datseris2017,
  author     = {Datseris, George},
  journal    = {Journal of Open Source Software},
  title      = {{DynamicalBilliards}.jl: {An} easy-to-use, modular and extendable {Julia} package for {Dynamical} {Billiard} systems in two dimensions.},
  year       = {2017},
  issn       = {2475-9066},
  month      = nov,
  number     = {19},
  pages      = {458},
  volume     = {2},
  abstract   = {Datseris, (2017), DynamicalBilliards.jl: An easy-to-use, modular and extendable Julia package for Dynamical Billiard systems in two dimensions., Journal of Open Source Software, 2(19), 458, doi:10.21105/joss.00458},
  comment    = {https://github.com/JuliaDynamics/DynamicalBilliards.jl},
  doi        = {10.21105/joss.00458},
  file       = {Full Text PDF:https\://joss.theoj.org/papers/10.21105/joss.00458.pdf:application/pdf},
  groups     = {paper-with-code},
  language   = {en},
  shorttitle = {{DynamicalBilliards}.jl},
  urldate    = {2021-12-05},
}

@Article{Saure2019,
  author    = {Saur√©, Denis and Vielma, Juan Pablo},
  journal   = {Operations Research},
  title     = {Ellipsoidal {Methods} for {Adaptive} {Choice}-{Based} {Conjoint} {Analysis}},
  year      = {2019},
  issn      = {0030-364X},
  month     = mar,
  number    = {2},
  pages     = {315--338},
  volume    = {67},
  abstract  = {Questionnaires for adaptive choice-based conjoint analysis aim at minimizing some measure of the uncertainty associated with estimates of preference parameters (e.g., partworths). Bayesian approaches to conjoint analysis quantify this uncertainty with a multivariate distribution that is updated after the respondent answers. Unfortunately, this update often requires multidimensional integration, which effectively reduces the adaptive selection of questions to impractical enumeration. An alternative approach is the polyhedral method for adaptive conjoint analysis, which quantifies the uncertainty through a (convex) polyhedron. The approach has a simple geometric interpretation and allows for quick credibility-region updates and effective optimization-based heuristics for adaptive question selection. However, its performance deteriorates with high response-error rates. Available adaptations to this method do not preserve all of the geometric simplicity and interpretability of the original approach. We show how, by using normal approximations to posterior distributions, one can include response error in an approximate Bayesian approach that is as intuitive as the polyhedral approach and allows the use of effective optimization-based techniques for adaptive question selection. This ellipsoidal approach extends the effectiveness of the polyhedral approach to the high response-error setting and provides a simple geometric interpretation (from which the method derives its name) of Bayesian approaches. Our results precisely quantify the relationship between the most popular efficiency criterion and heuristic guidelines promoted in extant work. We illustrate the superiority of the ellipsoidal method through extensive numerical experiments.},
  doi       = {10.1287/opre.2018.1790},
  file      = {Full Text PDF:https\://pubsonline.informs.org/doi/pdf/10.1287/opre.2018.1790:application/pdf},
  keywords  = {conjoint analysis, geometric methods, Bayesian models, mixed-integer programming},
  publisher = {INFORMS},
  urldate   = {2021-12-05},
}

@Article{Bertsimas2019,
  author    = {Bertsimas, Dimitris and Mi≈°iƒá, Velibor V.},
  journal   = {Operations Research},
  title     = {Exact {First}-{Choice} {Product} {Line} {Optimization}},
  year      = {2019},
  issn      = {0030-364X},
  month     = may,
  number    = {3},
  pages     = {651--670},
  volume    = {67},
  abstract  = {A fundamental problem faced by firms is that of product line design: given a set of candidate products that may be offered to a collection of customers, what subset of those products should be offered to maximize the profit that is realized when customers make purchases according to their preferences? In this paper, we consider the product line design problem when customers choose according to a first-choice rule and present a new mixed-integer optimization formulation of the problem. We theoretically analyze the strength of our formulation and show that it is stronger than alternative formulations that have been proposed in the literature, thus contributing to a unified understanding of the different formulations for this problem. We also present a novel solution approach for solving our formulation at scale, based on Benders decomposition, which exploits the surprising fact that Benders cuts for both the relaxation and the integer problem can be generated in a computationally efficient manner. We demonstrate the value of our formulation and Benders decomposition approach through two sets of experiments. In the first, we use synthetic instances to show that our formulation is computationally tractable and can be solved an order of magnitude faster for small- to medium-scale instances than the alternate, previously proposed formulations. In the second, we consider a previously studied product line design instance based on a real conjoint data set, involving over 3,000 candidate products and over 300 respondents. We show that this problem, which required a week of computation time to solve in prior work, is solved by our approach to full optimality in approximately 10 minutes.  The e-companion is available at https://doi.org/10.1287/opre.2018.1825.},
  comment   = {https://github.com/vvmisic/optimalPLD/},
  doi       = {10.1287/opre.2018.1825},
  file      = {Full Text PDF:https\://pubsonline.informs.org/doi/pdf/10.1287/opre.2018.1825:application/pdf},
  groups    = {paper-with-code},
  keywords  = {product line design, first-choice models, mixed-integer optimization, Benders decomposition},
  publisher = {INFORMS},
  urldate   = {2021-12-05},
}

@Article{Gugushvili2020,
  author    = {Gugushvili, Shota and Meulen, Frank van der and Schauer, Moritz and Spreij, Peter},
  journal   = {Brazilian Journal of Probability and Statistics},
  title     = {Nonparametric {Bayesian} estimation of a {H√∂lder} continuous diffusion coefficient},
  year      = {2020},
  issn      = {0103-0752},
  month     = aug,
  number    = {3},
  pages     = {537--579},
  volume    = {34},
  abstract  = {We consider a nonparametric Bayesian approach to estimate the diffusion coefficient of a stochastic differential equation given discrete time observations over a fixed time interval. As a prior on the diffusion coefficient, we employ a histogram-type prior with piecewise constant realisations on bins forming a partition of the time interval. Specifically, these constants are realizations of independent inverse Gamma distributed randoma variables. We justify our approach by deriving the rate at which the corresponding posterior distribution asymptotically concentrates around the data-generating diffusion coefficient. This posterior contraction rate turns out to be optimal for estimation of a H?lder-continuous diffusion coefficient with smoothness parameter \$0{\textless}{\textbackslash}lambda {\textbackslash}leq 1\$. Our approach is straightforward to implement, as the posterior distributions turn out to be inverse Gamma again, and leads to good practical results in a wide range of simulation examples. Finally, we apply our method on exchange rate data sets.},
  doi       = {10.1214/19-BJPS433},
  file      = {Full Text PDF:https\://projecteuclid.org/journals/brazilian-journal-of-probability-and-statistics/volume-34/issue-3/Nonparametric-Bayesian-estimation-of-a-H%c3%b6lder-continuous-diffusion-coefficient/10.1214/19-BJPS433.pdf:application/pdf},
  keywords  = {diffusion coefficient, Gaussian likelihood, non-parametric Bayesian estimation, Posterior contraction rate, pseudo-likelihood, Stochastic differential equation, Volatility},
  publisher = {Brazilian Statistical Association},
  urldate   = {2021-12-05},
}

@Article{MadlonKay2017,
  author    = {Madlon-Kay, Seth and Brent, Lauren and Montague, Michael and Heller, Katherine and Platt, Michael},
  journal   = {Brain Sciences},
  title     = {Using {Machine} {Learning} to {Discover} {Latent} {Social} {Phenotypes} in {Free}-{Ranging} {Macaques}},
  year      = {2017},
  month     = jul,
  number    = {7},
  pages     = {91},
  volume    = {7},
  abstract  = {Investigating the biological bases of social phenotypes is challenging because social behavior is both high-dimensional and richly structured, and biological factors are more likely to influence complex patterns of behavior rather than any single behavior in isolation. The space of all possible patterns of interactions among behaviors is too large to investigate using conventional statistical methods. In order to quantitatively define social phenotypes from natural behavior, we developed a machine learning model to identify and measure patterns of behavior in naturalistic observational data, as well as their relationships to biological, environmental, and demographic sources of variation. We applied this model to extensive observations of natural behavior in free-ranging rhesus macaques, and identified behavioral states that appeared to capture periods of social isolation, competition over food, conflicts among groups, and affiliative coexistence. Phenotypes, represented as the rate of being in each state for a particular animal, were strongly and broadly influenced by dominance rank, sex, and social group membership. We also identified two states for which variation in rates had a substantial genetic component. We discuss how this model can be extended to identify the contributions to social phenotypes of particular genetic pathways.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  doi       = {10.3390/brainsci7070091},
  file      = {Full Text PDF:https\://www.mdpi.com/2076-3425/7/7/91/pdf:application/pdf},
  keywords  = {machine learning, behavioral genetics, social neuroscience, animal models},
  language  = {en},
  publisher = {Multidisciplinary Digital Publishing Institute},
  url       = {https://www.mdpi.com/2076-3425/7/7/91},
  urldate   = {2021-12-05},
}

@Article{Pastell2017,
  author     = {Pastell, Matti},
  journal    = {Journal of Open Source Software},
  title      = {Weave.jl: {Scientific} {Reports} {Using} {Julia}},
  year       = {2017},
  issn       = {2475-9066},
  month      = mar,
  number     = {11},
  pages      = {204},
  volume     = {2},
  abstract   = {Weave is a tool for writing scientific reports using Julia (Bezanson et al. 2017). It allows writing of text, mathematics and code in a single document which can be run capturing results into a rich report. Output can include text using several markup languages, plots generated using one of the several Julia plotting libraries and other objects displayed using Julia‚Äôs multimedia output. The workflow is very similar to using Knitr (Xie 2015) R-package.

Weave supports noweb, markdown, script syntax for delimiting code from text in the source document and several output formats including Markdown and Latex. The output from code can be controlled using chunk options making it possible e.g. to hide code and only show output when needed as well as set a figure caption and figure size. The library also has methods for converting documents from all input formats to Jupyter notebooks and vice versa.

The package aims to support writing scientific papers and enable easy sharing of analysis in order to promote reproducible research. It also aims to enable simple writing of educational material, tutorials and blog posts.},
  comment    = {https://github.com/JunoLab/Weave.jl},
  doi        = {10.21105/joss.00204},
  file       = {Full Text PDF:https\://joss.theoj.org/papers/10.21105/joss.00204.pdf:application/pdf},
  groups     = {compat-with-LTS, paper-with-code},
  keywords   = {Scientific reports},
  language   = {en},
  shorttitle = {Weave.jl},
  urldate    = {2021-12-05},
}

@Article{Schaal2017,
  author  = {Schaal, Emily},
  journal = {Undergraduate Honors Theses},
  title   = {Center {Manifold} {Theory} and {Computation} {Using} a {Forward} {Backward} {Approach}},
  year    = {2017},
  month   = apr,
  url     = {https://scholarworks.wm.edu/honorstheses/1129},
}

@MastersThesis{Widmann2017,
  author   = {Widmann, David},
  school   = {Technische Universit√§t M√ºnchen},
  title    = {Quorum {Sensing} of {Pseudomonas} putida in {Continuous} {Cultures}},
  year     = {2017},
  abstract = {Bacteria of certain species communicate with each other to organise group-beneficial collective behaviour such as bioluminescence or swarming motility. The cell-to-cell communication of these bacteria is based on a cell-density dependent mechanism called quorum sensing (QS). For this process different mathematical models in the form of ordinary differential equations (ODEs), partial differential equations (PDEs), and delay differential equations (DDEs) have been proposed and studied in literature. In this thesis we consider a mathematical model of QS in {\textless}em{\textgreater}Pseudomonas putida{\textless}/em{\textgreater} IsoF ({\textless}em{\textgreater}P. putida{\textless}/em{\textgreater} IsoF) which was published by Buddrus-Schiemann et al. They conducted growth experiments of {\textless}em{\textgreater}P. putida{\textless}/em{\textgreater} IsoF under steady state conditions in a chemostat and could describe their measurements by a mathematical QS model of DDEs. We discuss the motivation of this model, building on well-known mathematical models for chemostat experiments and generic QS models. Moreover, we derive a modification of the QS model which accounts for subpopulations of {\textless}em{\textgreater}P. putida{\textless}/em{\textgreater} IsoF with different roles in the QS system. Buddrus-Schiemann et al. speculated about the existence of these subpopulations which could explain some of their surprising findings. After a short theoretical analysis of both QS models we investigate which numerical methods are suited for computing simulations of these models. We provide a general introduction to numerical DDE solvers and present DelayDiffEq.jl, an improved and rewritten DDE solver in Julia. The last part of this thesis is dedicated to the inverse problems of the QS models. We develop a suitable objective function for parameter estimation and apply regularization and global optimisation to deal with the ill-conditioning and non-convexity of the parameter estimation problem. Moreover, we determine structurally and practically non-identifiable parameters. Our parameter estimation yields slightly different parameter estimates that fit the experimental data better than the parameters published by Buddrus-Schiemann et al. However, the parameter estimates do not support the hypothesis of two subpopulations.},
  comment  = {https://github.com/SciML/DelayDiffEq.jl},
  eprint   = {https://mediatum.ub.tum.de/doc/1452085/1452085.pdf},
  groups   = {paper-with-code, compat-with-LTS},
  keywords = {Quorum Sensing, QS, Pseudomonas putida, Continuous Culture, Chemostat, Delay Differential Equation, DDE},
  url      = {https://mediatum.ub.tum.de/1452085?style=full_text&id=1452085&change_language=en},
  urldate  = {2021-12-05},
}

@Article{Liang2021,
  author        = {Liang, Jane W. and Sen, Saunak},
  journal       = {arXiv},
  title         = {Sparse matrix linear models for structured high-throughput data},
  year          = {2021},
  month         = feb,
  abstract      = {Recent technological advancements have led to the rapid generation of high-throughput biological data, which can be used to address novel scientific questions in broad areas of research. These data can be thought of as a large matrix with covariates annotating both rows and columns of this matrix. Matrix linear models provide a convenient way for modeling such data. In many situations, sparse estimation of these models is desired. We present fast, general methods for fitting sparse matrix linear models to structured high-throughput data. We induce model sparsity using an L\$\_1\$ penalty and consider the case when the response matrix and the covariate matrices are large. Due to data size, standard methods for estimation of these penalized regression models fail if the problem is converted to the corresponding univariate regression scenario. By leveraging matrix properties in the structure of our model, we develop several fast estimation algorithms (coordinate descent, FISTA, and ADMM) and discuss their trade-offs. We evaluate our method's performance on simulated data, E. coli chemical genetic screening data, and two Arabidopsis genetic datasets with multivariate responses. Our algorithms have been implemented in the Julia programming language and are available at https://github.com/senresearch/MatrixLMnet.jl.},
  annote        = {Comment: 35 pages, 7 figures},
  archiveprefix = {arxiv},
  comment       = {https://github.com/senresearch/MatrixLMnet.jl},
  eprint        = {1712.05767},
  file          = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1712.05767.pdf:application/pdf},
  groups        = {paper-with-code},
  keywords      = {Statistics - Computation},
  primaryclass  = {stat},
}

@Article{Lin2017,
  author   = {Lin, Youzuo and Le, Ellen B. and O'Malley, Daniel and Vesselinov, Velimir V. and Bui-Thanh, Tan},
  journal  = {Water Resources Research},
  title    = {Large-scale inverse model analyses employing fast randomized data reduction},
  year     = {2017},
  issn     = {1944-7973},
  number   = {8},
  pages    = {6784--6801},
  volume   = {53},
  abstract = {When the number of observations is large, it is computationally challenging to apply classical inverse modeling techniques. We have developed a new computationally efficient technique for solving inverse problems with a large number of observations (e.g., on the order of 107 or greater). Our method, which we call the randomized geostatistical approach (RGA), is built upon the principal component geostatistical approach (PCGA). We employ a data reduction technique combined with the PCGA to improve the computational efficiency and reduce the memory usage. Specifically, we employ a randomized numerical linear algebra technique based on a so-called ‚Äúsketching‚Äù matrix to effectively reduce the dimension of the observations without losing the information content needed for the inverse analysis. In this way, the computational and memory costs for RGA scale with the information content rather than the size of the calibration data. Our algorithm is coded in Julia and implemented in the MADS open-source high-performance computational framework (http://mads.lanl.gov). We apply our new inverse modeling method to invert for a synthetic transmissivity field. Compared to a standard geostatistical approach (GA), our method is more efficient when the number of observations is large. Most importantly, our method is capable of solving larger inverse problems than the standard GA and PCGA approaches. Therefore, our new model inversion method is a powerful tool for solving large-scale inverse problems. The method can be applied in any field and is not limited to hydrogeological applications such as the characterization of aquifer heterogeneity.},
  comment  = {https://github.com/madsjulia/Mads.jl/},
  doi      = {10.1002/2016WR020299},
  file     = {Full Text PDF:https\://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/2016WR020299:application/pdf},
  groups   = {paper-with-code, compat-with-LTS},
  keywords = {hydraulic inverse modeling, data reduction, randomization, geostatistical inversion},
  language = {en},
  urldate  = {2021-12-06},
}

@Article{Sinaie2017,
  author   = {Sinaie, Sina and Nguyen, Vinh Phu and Nguyen, Chi Thanh and Bordas, Stephane},
  journal  = {Advances in Engineering Software},
  title    = {Programming the material point method in {Julia}},
  year     = {2017},
  issn     = {0965-9978},
  month    = mar,
  pages    = {17--29},
  volume   = {105},
  abstract = {This article presents the implementation of the material point method (MPM) using Julia. Julia is an open source, multi-platform, high-level, high-performance dynamic programming language for technical computing, with syntax that is familiar to Matlab and Python programmers. MPM is a hybrid particle-grid approach that combines the advantages of Eulerian and Lagrangian methods and is suitable for complex solid mechanics problems involving contact, impact and large deformations. We will show that a Julia based MPM code, which is short, compact and readable and uses only Julia built in features, performs much better (with speed up of up to 8) than a similar Matlab based MPM code for large strain solid mechanics simulations. We share our experiences of implementing MPM in Julia and demonstrate that Julia is a very interesting platform for rapid development in the field of scientific computing.},
  doi      = {10.1016/j.advengsoft.2017.01.008},
  file     = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S0965997816302769/pdfft?md5=b95960c3691430285834af7845657d88&pid=1-s2.0-S0965997816302769-main.pdf&isDTMRedir=Y:application/pdf},
  groups   = {paper-with-code, compat-with-LTS},
  keywords = {Julia, Material point method (MPM), High-performance dynamic programming language, Technical computing},
  language = {en},
  url      = {https://www.sciencedirect.com/science/article/pii/S0965997816302769},
  urldate  = {2021-12-06},
}

@Article{Araujo2022,
  author    = {G. H. M. Ara{\'{u}}jo and R. Arefidamghani and R. Behling and Y. Bello-Cruz and A. Iusem and L.-R. Santos},
  journal   = {Fixed Point Theory and Algorithms for Sciences and Engineering},
  title     = {Circumcentering approximate reflections for solving the convex feasibility problem},
  year      = {2022},
  month     = {jan},
  number    = {1},
  volume    = {2022},
  abstract  = {The circumcentered-reflection method (CRM) has been applied for solving convex feasibility problems. CRM iterates by computing a circumcenter upon a composition of reflections with respect to convex sets. Since reflections are based on exact projections, their computation might be costly. In this regard, we introduce the circumcentered approximate-reflection method (CARM), whose reflections rely on outer-approximate projections. The appeal of CARM is that, in rather general situations, the approximate projections we employ are available under low computational cost. We derive convergence of CARM and linear convergence under an error bound condition. We also present successful theoretical and numerical comparisons of CARM to the original CRM, to the classical method of alternating projections (MAP), and to a correspondent outer-approximate version of MAP, referred to as MAAP. Along with our results and numerical experiments, we present a couple of illustrative examples.},
  comment   = {https://github.com/JuliaPapers/CRM-CFP},
  doi       = {10.1186/s13663-021-00711-6},
  groups    = {paper-with-code},
  keywords  = {Convex feasibility problem, Circumcentered-reflection method, Alternating projections, Approximate projection, Convergence rate, Error bound},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Elbert2022,
  author    = {Donald L. Elbert and Bruce W. Patterson and Brendan P. Lucey and Tammie L. S. Benzinger and Randall J. Bateman},
  journal   = {Communications Biology},
  title     = {Importance of {CSF}-based A$\upbeta$ clearance with age in humans increases with declining efficacy of blood-brain barrier/proteolytic pathways},
  year      = {2022},
  month     = {jan},
  number    = {1},
  volume    = {5},
  abstract  = {The kinetics of amyloid beta turnover within human brain is still poorly understood. We previously found a dramatic decline in the turnover of AŒ≤ peptides in normal aging. It was not known if brain interstitial fluid/cerebrospinal fluid (ISF/CSF) fluid exchange, CSF turnover, blood-brain barrier function or proteolysis were affected by aging or the presence of Œ≤ amyloid plaques. Here, we describe a non-steady state physiological model developed to decouple CSF fluid transport from other processes. Kinetic parameters were estimated using: (1) MRI-derived brain volumes, (2) stable isotope labeling kinetics (SILK) of amyloid-Œ≤ peptide (AŒ≤), and (3) lumbar CSF AŒ≤ concentration during SILK. Here we show that changes in blood-brain barrier transport and/or proteolysis were largely responsible for the age-related decline in AŒ≤ turnover rates. CSF-based clearance declined modestly in normal aging but became increasingly important due to the slowing of other processes. The magnitude of CSF-based clearance was also lower than that due to blood-brain barrier function plus proteolysis. These results suggest important roles for blood-brain barrier transport and proteolytic degradation of AŒ≤ in the development Alzheimer‚Äôs Disease in humans.},
  comment   = {https://zenodo.org/record/5775131},
  doi       = {10.1038/s42003-022-03037-0},
  groups    = {paper-with-code},
  keywords  = {Ageing, Alzheimer's disease, Computational models},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Bredikhin2022,
  author    = {Danila Bredikhin and Ilia Kats and Oliver Stegle},
  journal   = {Genome Biology},
  title     = {{MUON}: multimodal omics analysis framework},
  year      = {2022},
  month     = {feb},
  number    = {1},
  volume    = {23},
  abstract  = {Advances in multi-omics have led to an explosion of multimodal datasets to address questions from basic biology to translation. While these data provide novel opportunities for discovery, they also pose management and analysis challenges, thus motivating the development of tailored computational solutions. Here, we present a data standard and an analysis framework for multi-omics, MUON, designed to organise, analyse, visualise, and exchange multimodal data. MUON stores multimodal data in an efficient yet flexible and interoperable data structure. MUON enables a versatile range of analyses, from data preprocessing to flexible multi-omics alignment.},
  comment   = {https://github.com/scverse/Muon.jl},
  doi       = {10.1186/s13059-021-02577-8},
  groups    = {paper-with-code},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Stijnman2022,
  author    = {Peter R. S. Stijnman and Bart R. Steensma and Cornelis A. T. van~den Berg and Alexander J. E. Raaijmakers},
  journal   = {Scientific Reports},
  title     = {A perturbation approach for ultrafast calculation of {RF} field enhancements near medical implants in {MRI}},
  year      = {2022},
  month     = {mar},
  number    = {1},
  volume    = {12},
  abstract  = {Patients with medical implants often are deprived of magnetic resonance imaging examination because of safety risks. One specific risk is the enhancement of the radiofrequency fields around the medical implant potentially resulting in significant tissue heating and damage. The assessment of this enhancement is a computationally demanding task, with simulations taking hours or days to converge. Conventionally the source of the radiofrequency fields, patient anatomy, and the medical implant are simulated concurrently. To alleviate the computational burden, we reformulate a fast simulation method that views the medical implant as a small perturbation of the simulation domain without the medical implant and calculates the radiofrequency fields associated with this perturbation. Previously, this method required an extensive offline stage where the result is intractable for large simulation domains. Currently, this offline stage is no longer required and the method is completely online. The proposed method results in comparable radiofrequency fields but is orders of magnitude faster compared to standard simulation technique; the finite-difference time-domain, the finite-sums, and the finite element methods. This acceleration could enable patient-specific and potentially online radiofrequency safety assessment.},
  comment   = {https://github.com/JuliaPapers/DielectricUpdateTechnique.jl},
  doi       = {10.1038/s41598-022-08004-7},
  groups    = {paper-with-code},
  keywords  = {Applied physics, Computational science, Imaging techniques},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Schneider2022,
  author    = {Michael Schneider and Asis Shrestha and Agim Ballvora and Jens L√©on},
  journal   = {Plant Methods},
  title     = {High-throughput estimation of allele frequencies using combined pooled-population sequencing and haplotype-based data processing},
  year      = {2022},
  number    = {1},
  pages     = {1--18},
  volume    = {18},
  abstract  = {Background
In addition to heterogeneity and artificial selection, natural selection is one of the forces used to combat climate change and improve agrobiodiversity in evolutionary plant breeding. Accurate identification of the specific genomic effects of natural selection will likely accelerate transfer between populations. Thus, insights into changes in allele frequency, adequate population size, gene flow and drift are essential. However, observing such effects often involves a trade-off between costs and resolution when a large sample of genotypes for many loci is analysed. Pool genotyping approaches achieve high resolution and precision in estimating allele frequency when sequence coverage is high. Nevertheless, high-coverage pool sequencing of large genomes is expensive.

Results
Three pool samples (n‚Äâ=‚Äâ300, 300, 288) from a barley backcross population were generated to assess the population's allele frequency. The tested population (BC2F21) has undergone 18 generations of natural adaption to conventional farming practice. The accuracies of estimated pool-based allele frequencies and genome coverage yields were compared using three next-generation sequencing genotyping methods. To achieve accurate allele frequency estimates with low sequence coverage, we employed a haplotyping approach. Low coverage allele frequencies of closely located single polymorphisms were aggregated into a single haplotype allele frequency, yielding 2-to-271-times higher depth and increased precision. When we combined different haplotyping tactics, we found that gene and chip marker-based haplotype analyses performed equivalently or better compared with simple contig haplotype windows. Comparing multiple pool samples and referencing against an individual sequencing approach revealed that whole-genome pool re-sequencing (WGS) achieved the highest correlation with individual genotyping (‚â•‚Äâ0.97). In contrast, transcriptome-based genotyping (MACE) and genotyping by sequencing (GBS) pool replicates were significantly associated with higher error rates and lower correlations, but are still valuable to detect large allele frequency variations.

Conclusions
The proposed strategy identified the allele frequency of populations with high accuracy at low cost. This is particularly relevant to evolutionary plant breeding of crops with very large genomes, such as barley. Whole-genome low coverage re-sequencing at 0.03‚Äâ√ó‚Äâcoverage per genotype accurately estimated the allele frequency when a loci-based haplotyping approach was applied. The implementation of annotated haplotypes capitalises on the biological background and statistical robustness.},
  comment   = {https://doi.org/10.5281/zenodo.4304046},
  doi       = {10.1186/s13007-022-00852-8},
  groups    = {paper-with-code},
  keywords  = {Pool sequencing, Genotyping, Allele frequency estimation, Single nucleotide polymorphisms, Haplotype, Hordeum vulgare},
  publisher = {BioMed Central},
}

 
@Article{Muratore2022,
  author   = {Muratore, Giosu√® and Schneider, Csaba},
  journal  = {Journal of Symbolic Computation},
  title    = {Effective computations of the {Atiyah}-{Bott} formula},
  year     = {2022},
  issn     = {0747-7171},
  month    = sep,
  pages    = {164--181},
  volume   = {112},
  abstract = {We present an implementation of the Atiyah-Bott residue formula for M‚Äæ0,m(Pn,d). We use this implementation to compute a large number of Gromov-Witten invariants of genus 0, including intersection numbers of rational curves on general complete intersections. We also compute some numbers of rational contact curves satisfying suitable Schubert conditions. Our computations confirm known predictions made by Mirror Symmetry. The code we developed for these problems is publicly available and can also be used for other types of computations.},
  comment  = {https://github.com/mgemath/AtiyahBott.jl},
  doi      = {10.1016/j.jsc.2022.01.005},
  file     = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S0747717122000050/pdfft?md5=8f8f89e576d8bb9d5b68eae604f63562&pid=1-s2.0-S0747717122000050-main.pdf&isDTMRedir=Y:application/pdf},
  groups   = {paper-with-code},
  keywords = {Contact, Torus action, Bott formula, Enumeration, SageMath, Julia programming language},
  language = {en},
  url      = {https://www.sciencedirect.com/science/article/pii/S0747717122000050},
  urldate  = {2022-03-30},
}

 
@Article{Rivero2022,
  author     = {Rivero, Daniel and Fernandez-Blanco, Enrique and Pazos, Alejandro},
  journal    = {Expert Systems with Applications},
  title      = {{DoME}: {A} deterministic technique for equation development and {Symbolic} {Regression}},
  year       = {2022},
  issn       = {0957-4174},
  month      = jul,
  pages      = {116712},
  volume     = {198},
  abstract   = {Based on a solid mathematical background, this paper proposes a method for Symbolic Regression that enables the extraction of mathematical expressions from a dataset. Contrary to other approaches, such as Genetic Programming, the proposed method is deterministic and, consequently, does not require the creation of a population of initial solutions. Instead, a simple expression is grown until it fits the data. This method has been compared with four well-known Symbolic Regression techniques with a large number of datasets. As a result, on average, the proposed method returns better performance than the other techniques, with the advantage of returning mathematical expressions that can be easily used by different systems. Additionally, this method makes it possible to establish a threshold at the complexity of the expressions generated, i.e., the system can return mathematical expressions that are easily analyzed by the user, as opposed to other techniques that return very large expressions.},
  comment    = {https://github.com/danielriveroc/DoMEv1},
  doi        = {10.1016/j.eswa.2022.116712},
  file       = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S0957417422001889/pdfft?md5=f29381377772baa4c97b3b7f0e058b67&pid=1-s2.0-S0957417422001889-main.pdf&isDTMRedir=Y:application/pdf},
  groups     = {paper-with-code, OpenAccess, CC BY 4.0},
  keywords   = {Symbolic regression, Machine learning, Artificial intelligence},
  language   = {en},
  shorttitle = {{DoME}},
  url        = {https://www.sciencedirect.com/science/article/pii/S0957417422001889},
  urldate    = {2022-03-30},
}

 
@Article{Agrawal2022,
  author   = {Agrawal, Sudhanshu and Lee, Wonjun and Wu Fung, Samy and Nurbekyan, Levon},
  journal  = {Journal of Computational Physics},
  title    = {Random features for high-dimensional nonlocal mean-field games},
  year     = {2022},
  issn     = {0021-9991},
  month    = jun,
  pages    = {111136},
  volume   = {459},
  abstract = {We propose an efficient solution approach for high-dimensional nonlocal mean-field game (MFG) systems based on the Monte Carlo approximation of interaction kernels via random features. We avoid costly space-discretizations of interaction terms in the state-space by passing to the feature-space. This approach allows for a seamless mean-field extension of virtually any single-agent trajectory optimization algorithm. Here, we extend the direct transcription approach in optimal control to the mean-field setting. We demonstrate the efficiency of our method by solving MFG problems in high-dimensional spaces which were previously out of reach for conventional non-deep-learning techniques.},
  comment  = {https://github.com/SudhanshuAgrawal27/HighDimNonlocalMFG},
  doi      = {10.1016/j.jcp.2022.111136},
  file     = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S002199912200198X/pdfft?md5=e5e17f42df9381497291a1a9bf9f710f&pid=1-s2.0-S002199912200198X-main.pdf&isDTMRedir=Y:application/pdf},
  groups   = {paper-with-code},
  keywords = {Mean-field games, Nonlocal interactions, Random features, Optimal control, Hamilton-Jacobi-Bellman},
  language = {en},
  url      = {https://www.sciencedirect.com/science/article/pii/S002199912200198X},
  urldate  = {2022-03-30},
}

 
@Article{Bagci2022,
  author     = {Baƒücƒ±, Ali},
  journal    = {Computer Physics Communications},
  title      = {{JRAF}: {A} {Julia} package for computation of relativistic molecular auxiliary functions},
  year       = {2022},
  issn       = {0010-4655},
  month      = apr,
  pages      = {108276},
  volume     = {273},
  abstract   = {The evaluation of relativistic molecular integrals over exponential‚àítype spinor orbitals requires the use of relativistic auxiliary functions in prolate spheroidal coordinates, and has been recently achieved (Baƒücƒ± and Hoggan (2015) [14]). This process is used in the solution of the molecular Dirac equation for electrons moving in a Coulomb potential. A series of papers on a method for fully analytical evaluation of relativistic auxiliary functions has been published [2, 3, 4] From the perspective of computational physics, these studies demonstrate how to deal with the integrals of the product of power functions with non‚àíinteger exponents and incomplete gamma functions. The computer program package used to calculate these auxiliary functions with high accuracy is presented. It is designed using the Julia programming language and yields highly accurate results for molecular integrals over a wide range of orbital parameters and quantum numbers. Additionally, the program package facilitates the efficient calculation of the angular momentum coefficients that arise from the product of two normalized Legendre functions centered at different atomic positions, and the determination of the rotation angular functions used for both complex and real spherical harmonics. Sample calculations are performed for two‚àícenter one‚àíelectron integrals over non‚àíinteger Slater‚àítype orbitals, and the results prove the robustness of the package. Program summary Program Title: JRAF CPC Library link to program files: https://doi.org/10.17632/942xsbvfdf.1 Developer's repository link: https://github.com/abagciphys/JRAF.jl Licensing provisions: MIT Programming language: Julia programming language Supplementary material: An experimental version of the computer program package written in Mathematica programming language [5]. External routines/libraries: Nemo computer algebra package for the Julia programming language [6], Cuba multidimensional numerical integration using different algorithms in Julia [7]. Nature of problem: Relativistic molecular auxiliary function integrals result from the expression of a two‚àícenter two‚àíelectron Coulomb energy associated with a charge density. The Coulomb energy is transformed into kinetic energy integrals using Poisson's equation and the single‚àícenter potential, considering that the Laplace expansion for the Coulomb interactions is expressed in terms of normalized non‚àíinteger Slater‚àítype orbitals [1]. Using the resulting expression for the two‚àícenter two‚àíelectron integrals, relativistic auxiliary function integrals are derived in prolate ellipsoidal coordinates. These auxiliary functions are generalized to the entire set of physical potential operators for the Coulomb potential case. The integral of the relativistic auxiliary functions have no closed‚àíform solutions except that their parameters are integers. As such, the analytical evaluation of these functions is challenging. They are used in the solution of the matrix form representation of the molecular Dirac‚àíFock self‚àíconsistent field (SCF) equation. Solution method: A criterion that considers the symmetry properties of two‚àícenter two‚àíelectron molecular integrals is initially proposed [2]. This obviates the need for the computation of incomplete and complementary incomplete gamma functions, and utilizes their sum (P+Q=1). The resulting form of the integral of the relativistic molecular auxiliary functions is expressed in terms of the convergent series representation of incomplete beta functions. Recurrence relationships are then derived for each of these sub‚àífunctions [3]. The algorithm for computation of the auxiliary functions is based on the vectorization procedure defined in [4]. References [1]A. Baƒücƒ±, P.E. Hoggan, Phys. Rev. E 91 (2) (2015) 023303, https://link.aps.org/doi/10.1103/PhysRevE.91.023303.[2]A. Baƒücƒ±, P.E. Hoggan, Rend. Fis. Accad. Lincei 29 (1) (2018) 191‚Äì197, https://doi.org/10.1007/s12210-018-0669-8.[3]A. Baƒücƒ±, P.E. Hoggan, M. Adak, Rend. Fis. Accad. Lincei 29 (4) (2018) 765‚Äì775, https://doi.org/10.1007/s12210-018-0734-3.[4]A. Baƒücƒ±, P.E. Hoggan, Rend. Fis. Accad. Lincei 31 (4) (2020) 1089‚Äì1103, https://doi.org/10.1007/s12210-020-00953-3.[5]https://www.wolfram.com/mathematica/.[6]C. Fieker, W. Hart, T. Hofmann, F. Johansson, in: Proceedings of ISSAC '17, New York, ACM, 2017, pp. 157‚Äì164.[7]T. Hahn, Comput. Phys. Commun. 176 (11) (2007) 712‚Äì713, https://doi.org/10.1016/j.cpc.2007.03.006.},
  comment    = {https://github.com/abagciphys/JRAF.jl},
  doi        = {10.1016/j.cpc.2021.108276},
  file       = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S001046552100388X/pdfft?md5=f325722b92056ba608d4736b0ffe0270&pid=1-s2.0-S001046552100388X-main.pdf&isDTMRedir=Y:application/pdf},
  groups     = {paper-with-code},
  keywords   = {Dirac equation, Relativistic molecular auxiliary functions, Molecular integrals},
  language   = {en},
  shorttitle = {{JRAF}},
  url        = {https://www.sciencedirect.com/science/article/pii/S001046552100388X},
  urldate    = {2022-03-30},
}

 
@Article{Souza2022,
  author   = {Souza, Rodolfo and Jha, Achla and Calabrese, Salvatore},
  journal  = {Journal of Hydrology},
  title    = {Quantifying the hydrological impact of soil mulching across rainfall regimes and mulching layer thickness},
  year     = {2022},
  issn     = {0022-1694},
  month    = apr,
  pages    = {127523},
  volume   = {607},
  abstract = {Covering the soil surface with mulch is a cropland management practice that can provide several benefits to the soil environment, especially in rainfed systems. Soil mulching tends to enhance plant growth by reducing soil evaporation and potentially increasing transpiration, but its effectiveness vary widely across rainfall regimes and mulching materials. Here we investigate this variability using a process-based modeling framework coupling the dynamics of soil and mulching moisture and of crop growth. Supported by field observations under different mulching materials, we study the effectiveness of soil mulching in increasing transpiration and growth under different rainfall regimes and mulching layer thickness. The analysis suggests that in most rainfall scenarios soil mulching can increase plant transpiration by up to 100\% and reduce soil evaporation by up to 40\%. However, there exist rainfall conditions (low frequency and high intensity) under which soil mulching may cause lower transpiration. We also show that soil mulching is particularly beneficial during a dry spell, a phenomenon that is projected to occur more frequently in many climatic zones. In the event of a dry spell during the growing season, soil mulching helps maintain moist conditions for longer, hence limiting the negative effects on plant transpiration and growth. The analysis helps better understand the role of soil mulching on transpiration and crop growth and provides important information for improving soil mulching depending on mulching material and the site-specific rainfall regime.},
  comment  = {https://github.com/calabresehydrologylab/SoilMulch.jl},
  doi      = {10.1016/j.jhydrol.2022.127523},
  groups   = {paper-with-code},
  keywords = {Soil moisture, Evapotranspiration, Conservation agriculture, Rainfed agriculture, Dry spells},
  language = {en},
  url      = {https://www.sciencedirect.com/science/article/pii/S0022169422000981},
  urldate  = {2022-03-30},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:paper-with-code\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:compat-with-LTS\;0\;1\;0x00ff00ff\;\;Compat with LTS release: v1.6.4 (2021-11-19)\;;
1 StaticGroup:OpenAccess\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:CC BY 4.0\;0\;1\;0x8a8a8aff\;\;https://creativecommons.org/licenses/by/4.0/\;;
}
